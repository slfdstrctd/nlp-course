{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/cu118 -q"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:34:25.552836100Z",
     "start_time": "2023-10-24T21:34:22.915949900Z"
    }
   },
   "id": "d5c4ccfbb8067a1e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas spacy scikit-learn tqdm tensorflow -q"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T18:17:27.550478300Z",
     "start_time": "2023-10-24T18:17:25.538520900Z"
    }
   },
   "id": "fd1bf2e689430d2c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T19:42:19.411328800Z",
     "start_time": "2023-10-24T19:42:19.406802500Z"
    }
   },
   "id": "d526b547f144d3ea"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "(44898, 5)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = pd.read_csv('True.csv')\n",
    "fake = pd.read_csv('Fake.csv')\n",
    "\n",
    "fake[\"is_fake\"] = 1\n",
    "true[\"is_fake\"] = 0\n",
    "\n",
    "df = pd.concat([true, fake])\n",
    "del fake, true\n",
    "\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T20:10:28.229706400Z",
     "start_time": "2023-10-24T20:10:27.173247700Z"
    }
   },
   "id": "c6c877a75bcdeb21"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "NUM_WORDS = 10000\n",
    "SENTENCE_LENGTH = 100\n",
    "EMBED_DIM = 1000\n",
    "random_state = 42\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return text.progress_apply(\n",
    "        lambda x: \" \".join(\n",
    "            token.lemma_.lower() for token in nlp(x) if\n",
    "            not token.is_stop\n",
    "            and not token.is_punct\n",
    "            and not token.is_digit\n",
    "            and not token.like_email\n",
    "            and not token.like_num\n",
    "            and not token.is_space\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T20:50:46.510654500Z",
     "start_time": "2023-10-24T20:50:45.637368700Z"
    }
   },
   "id": "479b5fc84b231226"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44898/44898 [33:12<00:00, 22.53it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14min 9s\n",
      "Wall time: 33min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['cleaned_text'] = df['title'] + \" \" + df['text']\n",
    "df['cleaned_text'] = preprocess_text(df['cleaned_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T20:46:51.217728100Z",
     "start_time": "2023-10-24T20:13:38.009751900Z"
    }
   },
   "id": "733662037d403590"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['is_fake'], test_size=0.2,\n",
    "                                                    random_state=random_state)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T20:50:53.369469100Z",
     "start_time": "2023-10-24T20:50:52.461611500Z"
    }
   },
   "id": "259949b64fab75b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "tokenizer.fit_on_texts(df['cleaned_text'])\n",
    "train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "x_train = pad_sequences(train_seq, maxlen=SENTENCE_LENGTH)\n",
    "x_test = pad_sequences(test_seq, maxlen=SENTENCE_LENGTH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b3be3b96ebababe"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = torch.tensor(data).to(torch.int64)\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.label[index]\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "torch.manual_seed(random_state)\n",
    "train_dataset = SpamDataset(x_train, y_train.to_numpy())\n",
    "test_dataset = SpamDataset(x_test, y_test.to_numpy())\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T20:51:48.900679900Z",
     "start_time": "2023-10-24T20:51:37.029425600Z"
    }
   },
   "id": "40df0a0b83eb4877"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        self.embed = nn.Embedding(NUM_WORDS, embed_dim)\n",
    "        self.conv1 = nn.Conv2d(1, 1, 3)\n",
    "        self.conv2 = nn.Conv2d(1, 1, 3)\n",
    "        self.conv3 = nn.Conv2d(1, 1, 3)\n",
    "        self.fc = nn.Linear(93436, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        out = out.unsqueeze(1)\n",
    "        out = F.relu(self.conv1(out))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:43:38.940842300Z",
     "start_time": "2023-10-24T21:43:38.935825500Z"
    }
   },
   "id": "fdff1ed0c2c18a44"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, seq_len):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(seq_len * hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = torch.reshape(x, (x.size(0), -1,))\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:43:39.448733800Z",
     "start_time": "2023-10-24T21:43:39.429099800Z"
    }
   },
   "id": "88b0ac0d25d89018"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, epochs, train_dataloader, test_dataloader, device, criterion, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0\n",
    "            correct_predictions = 0\n",
    "            total = 0\n",
    "            for i, (inputs, targets) in enumerate(tqdm(self.train_dataloader)):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "            train_loss = running_loss / len(train_dataloader)\n",
    "            train_accuracy = correct_predictions / total\n",
    "            print(f'Epoch: {epoch + 1}/{self.epochs}, Loss: {train_loss:.6f}, Train accuracy: {train_accuracy:.6f}')\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in self.test_dataloader:\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "        val_loss /= len(self.test_dataloader)\n",
    "        val_accuracy = correct_predictions / len(test_dataset)\n",
    "\n",
    "        print(f'Validation loss: {val_loss:.6f}, Validation accuracy: {val_accuracy:.3f}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:43:40.105724200Z",
     "start_time": "2023-10-24T21:43:40.099635400Z"
    }
   },
   "id": "1ff5c6f434481e5c"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "CNN_model = CNN(EMBED_DIM).to(device)\n",
    "CNN_optimizer = torch.optim.Adam(CNN_model.parameters(), lr=0.001)\n",
    "CNN_criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:43:40.690903800Z",
     "start_time": "2023-10-24T21:43:40.634546600Z"
    }
   },
   "id": "8c6869de049e549b"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "CNN_trainer = Trainer(CNN_model, 5, train_dataloader, test_dataloader, device, CNN_criterion, CNN_optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:43:41.221028100Z",
     "start_time": "2023-10-24T21:43:41.198361500Z"
    }
   },
   "id": "485cc1c8e5a5323c"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:12<00:00, 11.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Loss: 0.752914, Train accuracy: 0.597778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:12<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/5, Loss: 0.163411, Train accuracy: 0.941199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:12<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5, Loss: 0.025244, Train accuracy: 0.993513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:12<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5, Loss: 0.005218, Train accuracy: 0.999360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:12<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5, Loss: 0.003256, Train accuracy: 0.999304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CNN_trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:44:43.649282600Z",
     "start_time": "2023-10-24T21:43:42.023712900Z"
    }
   },
   "id": "f8b488bdd222f85b"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.067560, Validation accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "CNN_trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:44:44.029593400Z",
     "start_time": "2023-10-24T21:44:43.650286200Z"
    }
   },
   "id": "bcba9d3eafb2cf40"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "LSTM_model = LSTM(vocab_size=NUM_WORDS, embedding_dim=EMBED_DIM, hidden_dim=100, n_layers=3,\n",
    "                  seq_len=SENTENCE_LENGTH).to(device)\n",
    "LSTM_optimizer = torch.optim.Adam(LSTM_model.parameters(), lr=0.001)\n",
    "LSTM_criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:36:48.860443100Z",
     "start_time": "2023-10-24T21:36:48.784819400Z"
    }
   },
   "id": "636f9382b19109da"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "LSTM_trainer = Trainer(LSTM_model, 2, train_dataloader, test_dataloader, device, LSTM_criterion, LSTM_optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:36:48.868505300Z",
     "start_time": "2023-10-24T21:36:48.860443100Z"
    }
   },
   "id": "2f2f785fd6f39615"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:04<00:00, 29.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2, Loss: 0.142017, Train accuracy: 0.942007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:04<00:00, 29.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/2, Loss: 0.020420, Train accuracy: 0.993457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LSTM_trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:36:58.342650400Z",
     "start_time": "2023-10-24T21:36:48.864964100Z"
    }
   },
   "id": "8fd81cb422cd7f40"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.041763, Validation accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "LSTM_trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:36:58.819511900Z",
     "start_time": "2023-10-24T21:36:58.336108200Z"
    }
   },
   "id": "734709f28314625f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eb9f6c6420c41c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
